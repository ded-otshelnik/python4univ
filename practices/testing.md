# Лабораторная работа 2. Тестирование кода на Python

## Содержание

## Тестирование и TDD

По мере разработки ПО и приложений рано или поздно возникает потребность в оценке поведения программы или какой-то её части, т.е. возникает потребность в **тестировании**. Это происходит по тому, что по мере роста кода отлавливать баги и ошибки (обнаруженные и/или потенциальные) становится задачей проблематичной, а в некоторых ситуациях (например, проект с легаси-кодом) - невозможной.

**Тестирование** - проверка соответствия реальных и ожидаемых результатов поведения программы, проводимая на конечном наборе тестов. Цель тестирования - проверка соответствия ПО предъявляемым требованиям, поиск очевидных ошибок в программном обеспечении, которые должны быть выявлены до того, как их обнаружат пользователи программы.

С началом 2000-х в среде программистов получила распространение концепция **разработки через тестирование (Test-Driven Development, TDD)**, введенная в оборот [Кентом Беком](https://habr.com/ru/companies/jugru/articles/580976/). Процесс разработки в данной методологии заключается в следующем:

1. Написать падающий тест, который покажет, какую функциональность необходимо добавить и как поведением она должна обладать;
2. Написать код, минимально достаточным для того, чтобы тест проходил. На этой стадии код не обязан быть элегантным или чистым;
3. Провести рефакторинг кода. Тесты позволяют безопасно "чистить" код, сделать его более читаемым и поддерживаемым

<img src="images/tdd.png" alt="tdd" width="500"/>

На практике программист **никогда не пишет сразу правильный код**: при разработке неизбежно возникают ошибки/баги, на отладку требуется затратить порой не меньшее время, чем было потрачено на само написание кода. Более того, не всегда очевидно **где возникает ошибка и из-за чего**, что также ведет к увеличению времени.

На первый взгляд кажется, что использование TDD приводит к написанию большего кода (иногда соотношение между тестами и самим кодом в промышленных проектах составляет 1:2 или 1:3), а следовательно, и увеличению времени выполнения проекта; если говорится о программисте, который не работает по TDD, то это скорее верно. Однако, при активном использовании методологии скорость разработки будет быстрее.

Благодаря тестированию можно **изолировать** ошибки, которые возникают в ходе выполнения программы, тем самым позволяя идентифицировать функциональность, которая является некорректной и должна быть исправлена. Также тесты могут выступать в виде своеобразной **спецификации**, т.е. как документация и пример, доказывающий работоспособность кода.

Таким образом, TDD позволяет:

1. Уменьшать время отладки;
2. Рефакторить код с гарантией работоспособности;
3. Получать данные о состоянии системы на основе тестов.

## Виды тестов и их основные характеристики

Всего существует несколько типов тестов, в частности:

1. Юнит-тест;
2. Интеграционный тест;
3. Сквозной тест.

### Юнит-тест

Существует множество определений юнит-тестов, однако все они сводятся к трем атрибутам.

**Юнит-тест** - автоматизированный тест, который:

1. Проверяет правильность работы некоторого фрагмента кода, называемого **юнитом**;
2. Делает это быстро;
3. Поддерживает изоляцию от другого кода.

Если с первыми двумя пунктами все более-менее понятно, то насчет третьего пункта имеют место разногласия, поскольку вопрос изоляции важен в контексте юнит-тестов. Вопрос изоляции - ключевое разногласие между двумя школами юнит-тестирования: **классической** и **лондонской** (или **мокистской**, от слова mock).

Лондонская школа описывает **изоляцию тестироваемого кода от его зависимостей**. То есть, если тестируемая функция или класс имеет в качестве зависимостей другие классы, то зависимости должны быть заменены на **тестовые заглушки** - легковесную версию класса-зависимости, удобной для тестов - или **моки** - подкласс тестовых заглушек, которые позволяют проанализировать взаимодействие между классами.

Преимущества подхода:

1. В случае падения точно известно место возникновения ошибки;
2. Возможность разбить граф объектов (классов, решающих одну задачу);
3. Простое правило тестирования: проверять один класс за раз (юнит не может быть больше 1 класса).

Классическая школа полагает изоляцию как **изоляцию тестов друг от друга** таким образом, что тесты могут быть выполнены параллельно и независимо. Классический подход не запрещает тестировать несколько классов за раз, если они не используют **совместные зависимости** - зависимости, к которым имеет доступ более одного теста - через которые тесты могут влиять на результат выполнения. Типичные примеры совместных состояний - внепроцессные зависимости - базы данных, файловая система, и т.п.

Такой подход к изоляции уменьшает объем моков и тестовых заглушек, причем если тест получает свою версию совместной зависимости (свою БД через контейнер Docker, класс-одиночка, для которого тесты не применяют паттерн Singleton, и т.п.), то такая зависимость становится приватной и может быть использоваться в юнит-тестах.

### Интеграционный тест и сквозной тест

**Интеграционный тест** - тест, который не удовлетворяет хотя бы одному критерию юнит-теста. На практике они всегда проверяют как система работает в интеграции с внепроцессными зависимостями. Если юнит-тесты проверяют доменную область, в котором работает приложение, то интеграционные тесты проверяют код, связывающий доменную область с внепроцессными зависимостями.

**Сквозной тест** - тест, который проверяет систему вместе с ее подсистемами, внепроцессными зависимостями и т.д. т начала и до конца для верификации выполнения полного производственного сценария.

Достаточно любопытно, что лондонская школа юнит-тестирования, исходя из описанных соображений по изоляции, полагает, что тест, который использует любой реальный объект-коллаборатор, является интеграционным из-за третьего критерия, в то время как классическая школа будет воспринимать такой тест как юнит-тест.

В интеграционных тестах важно понимать как внепроцессных зависимостей должны проверяться. Все внепроцессные зависимости делятся на два типа: **управляемые** (под полным контролем разработчика, например, БД) и **неуправляемые** (не под полным контролем, например почтовый сервер SMTP, результат взаимодействия виден другим). В случае управляемых зависимостей чаще всего взаимодействие является скрытым и не видны внешнему миру, т.е. взаимодействие является **деталью имплементации**, а такую зависимость можно использовать как реальную, не заменяя ее; в случае неуправляемых зависимостей взаимодействие является частью **наблюдаемого поведения (контракта)**, что ведет к необходимости их замены на моки.

## Тестирование в Python: pytest и unittest

Для языка программирования Python существуют множество инструментов тестирования, которые достаточно легко позволяют создавать и запускать тесты, проверять производительность, и много чего еще.

Обычно тесты в Python реализуются через модули **[pytest](https://docs.pytest.org/en/stable/)**, **[unittest](https://docs.python.org/3/library/unittest.html)** и **[doctest](https://docs.python.org/3/library/doctest.html)**, которые предоставляют широкий функционал для написания юнит-тестов.

### Pytest

Рассмотрим тривиальный тест:

```python
def test_answer() -> None:
    assert 2 + 2 == 5, "2 + 2 must be 4, not 5"
```

Простейший тест реализовывается следующим образом: в Python есть оператор `assert`, который позволяет проверять булевские условия; если условие assert-a не выполняется, то генерируется `AssertionError`, и если присутствует описание, то оно тоже выводится.

Такой тест можно выполнить через утилиту **pytest**, введя ``pytest <filename>`` (или ``pytest .``) в терминал. В результате будет что-то похожее на это:

![pytest](images/pytest_simple.png)

Важно: по умолчанию pytest ищет файлы (и методы внутри него), содержащие в названии `test` в начале или конце (только для файлов), т.е. в формате `test_*.py` или `*_test.py` для файлов и `test*` для функций.

Рассмотрим теперь более похожий на реальный тест и его структуру:

```python
def factorial(n: int) -> int:
    """Calculates factorial of n"""
    if n in [0, 1]:
        return 1
    return n * factorial(n - 1)


def test_factorial() -> None:
    # arrange
    input = 5
    expected = 120
    
    # act
    got = factorial(input)
    
    # assert
    assert expected == got, f"Expected {expected}, got {got}"
```

В данном тесте присутствует паттерн **Arrange/Act/Assert(AAA)**, который рекомендуется применять при написании тестов:

1. **Arrange** - входные данные, которые принимает функция для работы (соединения с БД, параметры методов, и т.п.) и целевые данные, которые должны быть в результате выполнения функции;
2. **Act** - желаемое поведение: это может быть вызов функции, HTTP запрос по REST API, взаимодействие с веб-страницей.
3. **Assert** - проверка ожидаемого результата; иногда требуется один assert для проверки чисел или строк, иногда - комплексная верификация множества аспектов системы.

Тесты можно параметризовать для группировки схожих тестов:

```python
@pytest.mark.parametrize(
    ("number", "expected"),
    [
        (0, 1),
        (1, 1),
        (5, 120),
    ],
)
def test_factorial(number: int, expected: int) -> None:
    got = factorial(number)
    
    assert expected == got
```

Некоторые тесты можно пропускать во время выполнения тестирования, если выполняется условие, или вовсе выключать тест, который не является в данный момент нужным, но в будущем может использовать в случае изменения кода:

```python
@pytest.mark.skip(
  reason = "Известная ошибка в версии библиотеки 1.2.3, исправление ожидается в следующем релизе",
)
def test_some_function() -> None:
    assert some_function() == expected_result

@pytest.mark.skipif(
    sys.platform == "win32", 
    reason = "Тест не поддерживается на Windows",
)
def test_unix_specific_function() -> None:
    assert unix_specific_function() == expected_result
```

Для создания тестовых заглушек можно воспользоваться специальными функциями, называемыми **фикстурами**, которые будут внедрены автоматически как требуемые зависимости:

```python
@pytest.fixture()
def price_manager() -> PriceManager:
    return PriceManager(
        x_price_source = StubXPriceSource(return_result = Decimal("150.00")),
        y_price_source = StubYPriceSource(return_result = Decimal("220.00")),
    )

    
class TestPriceManager: 
    def test_get_price_if_product_type_eq_x(self, price_manager: PriceManager) -> None:
        product = Product(type = "x")
        
        got = price_manager.get_price(product)
        
        assert got == Decimal("150.00")
    ...
```

Преимущество фикстур заключается в том, что они являются достаточно гибкими, они могут:

1. Они могут использоваться без необходимости импортирования (если фикстура в другом файле определена);
2. Фикстура может вызываться по требованию (раз в сессию тестирования, каждый раз при вызове тестовой функции, и т.п);
3. Фикстуры можно использоваться внутри других фикстур;
4. Фикстура параметризуема (можно передавать аргументы в нее).

### Unittest

**Unittest** является фреймворком для юнит-тестирования, который похож на фреймворк JUnit под Java и имеет схожую логику работы. Он поддерживает автоматизированные тесты, агрегацию тестов, гибкую конфигурацию и т.д.

В рамках фреймворка группа тестов называется **тестовыми кейсами (test case)**, который может быть **позитивными** (проверка кода при нормальных условиях) и  **негативными** (код проверяется на ситуациях некорректного/неожиданного ввода или пограничных ситуаций). В коде test cases реализуется в виде класса, который наследуется от класса `TestCase`.

Пусть есть некоторая функция, которая будет протестирована:

```python
def my_sum(arg):
    total = 0
    for val in arg:
        total += val
    return total
```

Тест для такой функции через unittest будет выглядеть следующим образом:

```python

import unittest

def my_sum(arg):
    total = 0
    for val in arg:
        total += val
    return total

class TestSum(unittest.TestCase):
    def test_list_int(self):
        """
        Test that it can sum a list of integers
        """
        data = [1, 2, 3]
        expected = 6

        result = my_sum(data)

        self.assertEqual(result, expected)

if __name__ == '__main__':
    unittest.main()

```

В отличие от pytest здесь используется assert-методы базового класса при проверке. TestCase обладает широким спектром assert-методов, которые помогают разбирать разные аспекты поведения проверяемого кода. Пусть есть класс-калькулятор, который отрабатывает пограничные ситуации наподобия деления на ноль, или передачу некорректного параметра:

```python
class Operation:

    def __init__(self):
       pass

    def add(self,a,b):
      if not isinstance(a, (int, float)):
         raise ValueError("Value must be either an integer or a float.")
      
      if not isinstance(b, (int, float)):
         raise ValueError("Value must be either an integer or a float.")
      return a+b
    
    def minus(self,a,b):
      if not isinstance(a, (int, float)):
         raise ValueError("Value must be either an integer or a float.")
      
      if not isinstance(b, (int, float)):
         raise ValueError("Value must be either an integer or a float.")
      return a-b
    
    def mul(self,a,b):
      if not isinstance(a, (int, float)):
         raise ValueError("Value must be either an integer or a float.")
      
      if not isinstance(b, (int, float)):
         raise ValueError("Value must be either an integer or a float.")
      return a*b
    
    def div(self,a,b):
      if not isinstance(a, (int, float)):
         raise ValueError("Value must be either an integer or a float.")
      if not isinstance(b, (int, float)):
         raise ValueError("Value must be either an integer or a float.")
    
      if b==0:
         raise ValueError("Zero division error")
      return a/b
```

Тогда можно написать целое множество тестов, которое покрывает код:

```python
import unittest
import sample

class TestSample(unittest.TestCase):  

    def __init__(self, methodName='runTest'):  
        super().__init__(methodName)  

        # Test data 
        self.a1 = 20
        self.a2 = 'Ram'
        self.b1 = 10
        self.b2 = 0
        self.checker = sample.Operation()  # Creating the object

    def test_add(self):
        # Positive test case
        result = self.checker.add(self.a1, self.b1)
        self.assertEqual(result, 30)

        # Negative test case for data type
        with self.assertRaises(ValueError) as context:
            self.checker.add(self.a2, self.b1)
        self.assertEqual(str(context.exception), "Value must be either an integer or a float.")

    def test_minus(self):
        # Positive test case
        result = self.checker.minus(self.a1, self.b1)
        self.assertEqual(result, 10)

        # Negative test case for data type
        with self.assertRaises(ValueError) as context:
            self.checker.minus(self.a2, self.b1)
        self.assertEqual(str(context.exception), "Value must be either an integer or a float.")

    def test_mul(self):
        # Positive test case
        result = self.checker.mul(self.a1, self.b1)
        self.assertEqual(result, 200)

        # Negative test case for data type
        with self.assertRaises(ValueError) as context:
            self.checker.mul(self.a2, self.b1)
        self.assertEqual(str(context.exception), "Value must be either an integer or a float.")

    def test_div(self):
        # Positive test case
        result = self.checker.div(self.a1, self.b1)
        self.assertEqual(result, 2)

        # Negative test case for data type
        with self.assertRaises(ValueError) as context:
            self.checker.div(self.a2, self.b1)
        self.assertEqual(str(context.exception), "Value must be either an integer or a float.")

        # Negative test case for zero division
        with self.assertRaises(ValueError):
            self.checker.div(self.a1, self.b2)

if __name__ == "__main__":
    unittest.main()    
```

Запускаются тесты следующей командой:

```bash
python -m unittest <filemame>
```

Если требуется запускать конкретные тесты или классы, то можно выполнить это следующим образом:

```bash
# тестируется два модуля
python -m unittest test_module1 test_module2
# тестируются все тесты данного класса
python -m unittest test_module.TestCase
# тестируется только один тест
python -m unittest test_module.TestCase.test_method
```

Для мокирования и создания тестовых заглушек можно воспользоваться подмодулем [unittest.mock](https://docs.python.org/3/library/unittest.mock.html), который реализует данную функциональность через классы **Mock** и **MagicMock** и декоратор `@patch`.

Пусть есть функция, которая проверяет является ли дата рабочим днем (в простой ситуации, без учета праздников или других особенностей):

```python
import datetime

def is_weekday():
    today = datetime.date.today()
    return 0 <= today.weekday() < 5

```

Напишем простые тесты для проверки кода:

```python
import datetime
import unittest
from unittest.mock import patch

import weekday

class TestWeekday(unittest.TestCase):
    @patch("weekday.datetime")
    def test_is_weekday(self, mock_datetime):
        mock_datetime.date.today.return_value = datetime.date(2024, 4, 4)
        self.assertTrue(weekday.is_weekday())

    @patch("weekday.datetime")
    def test_is_weekend(self, mock_datetime):
        mock_datetime.date.today.return_value = datetime.date(2024, 4, 6)
        self.assertFalse(weekday.is_weekday())

if __name__ == "__main__":
    unittest.main()
```

При помощи декоратора `@patch` можно создавать моки для каждой функции, оборачивая модуль datetime, который вызывается в модуле weekday (таким нехитрым образом можно заменять зависимости в виде модулей и тестировать целевой код). Созданный мок принимается тестовыми методами как параметр `mock_datetime`, при этом параметр будет вести себя как модуль для тестируемого модуля. Указывая нужные данные в качестве тех, которые должны быть возвращены моком, можно выполнять тесты.

Примечательно, что pytest умеет выполнять тесты, реализованные через модуль unittest, а в свою очередь тесты на unittest поддерживают применение фичей из pytest, например, фикстуры.

### Doctest

**Doctest** - инструмент тестирования, который выполняет тесты, исходя из **docstrings, написанных в определенных форматах**.

Как это делается: пусть реализуется факториал. Тогда для того, чтобы тестирование через doctest сработало, нужно отформатировать соответствующий docstring следующим образом:

```python
"""
This is the "example" module.

The example module supplies one function, factorial().  For example,

>>> factorial(5)
120
"""

def factorial(n):
    """Return the factorial of n, an exact integer >= 0.

    >>> [factorial(n) for n in range(6)]
    [1, 1, 2, 6, 24, 120]
    >>> factorial(30)
    265252859812191058636308480000000
    >>> factorial(-1)
    Traceback (most recent call last):
        ...
    ValueError: n must be >= 0

    Factorials of floats are OK, but the float must be an exact integer:
    >>> factorial(30.1)
    Traceback (most recent call last):
        ...
    ValueError: n must be exact integer
    >>> factorial(30.0)
    265252859812191058636308480000000

    It must also not be ridiculously large:
    >>> factorial(1e100)
    Traceback (most recent call last):
        ...
    OverflowError: n too large
    """

    import math
    if not n >= 0:
        raise ValueError("n must be >= 0")
    if math.floor(n) != n:
        raise ValueError("n must be exact integer")
    if n+1 == n:  # catch a value like 1e300
        raise OverflowError("n too large")
    result = 1
    factor = 2
    while factor <= n:
        result *= factor
        factor += 1
    return result


if __name__ == "__main__":
    import doctest
    doctest.testmod()
```

Если вы запустите скрипт через командную строку, то вы ничего не заметите (если нет ошибок в docstring):

```bash
$ python example.py
$
```

Если передать параметр `-v`, то тогда можно увидеть детальный лог с результатами тестов:

```bash
$ python example.py -v
Trying:
    factorial(5)
Expecting:
    120
ok
Trying:
    [factorial(n) for n in range(6)]
Expecting:
    [1, 1, 2, 6, 24, 120]
ok
...
```

Подход с инкапсуляцией тестового кода внутри docstring может принести дополнительную пользу, если проект использует **автоматизированные генераторы документации** такие, как **MkDocs** или **Sphinx**, которые очень популярны для создания полноценных веб-страниц с подробным описанием проекта.

## Автоматизация тестирования: tox

Тестирование позволяет проверять ошибки, а также контролировать качество кода, но вот вопрос: **будет ли работать тестируемый код во всех средах Python и со всеми версиями зависимостей/библиотек?**.

В общем случае, ответ - нет, поскольку у Python нет полноценной и нормально работающей обратной совместимости, из-за чего возникает множество проблем при обновлении программных сред, версий библиотек и т.д.

Для устранения проблем с программным окружением, а также автоматизации тестирования в разных средах, был разработан инструмент **[Tox](https://tox.wiki/en/4.24.2/)**. Основной целью этой утилиты является общее управление виртуальными средами при тестировании, чтобы проекты собирались и развертывались корректно в разных виртуальных средах (не только в плане версий библиотек или языка, но и имплементаций самого Python), автоматизация тестов, а также интеграция с CI (Continuous Integration - CI) сервисами.

Чтобы запустить tox для проекта, нужно определить **конфигурационный файл** с информацией об инструментах, которые должны быть использованы и как подготовить под них тестовую среду. Обычно такой файл называется **tox.ini** или **tox.toml**. В случае toml-файла это выглядит следующим образом:

```toml
requires = ["tox>=4"]
env_list = ["lint", "type", "3.13", "3.12", "3.11"]

[env_run_base]
description = "run unit tests"
deps = [
    "pytest>=8",
    "pytest-sugar"
]
commands = [["pytest", { replace = "posargs", default = ["tests"], extend = true }]]

[env.lint]
description = "run linters"
skip_install = true
deps = ["black"]
commands = [["black", { replace = "posargs", default = ["."], extend = true} ]]

[env.type]
description = "run type checks"
deps = ["mypy"]
commands = [["mypy", { replace = "posargs", default = ["src", "tests"], extend = true} ]]
```

Первые две строки выполняются для всех сред и определяет как tox выполняется. Здесь обычно указывается информация о версии tox или файловый путь до проекта.

``[env_run_base]`` таблица и ее настройки **автоматически наследуются** всеми средами, кроме ситуаций переопределения конкретных настроек. Названия тестовых сред должны содержать цифры, буквы на английском языке или тире. Если в названии присутствует `pyNM`, то полагается, что среда должна быть запущена на стандартной имплементации Python с версией *N.M* (например, 3.11); данное правило аналогично работает и для других имплементаций Python (СPython, Jython, и т.д.).

## Задания
